{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c182e663-c18b-4e4f-aca1-46c2856e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, simpledialog, filedialog\n",
    "from threading import Thread\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader, PDFPlumberLoader, TextLoader, UnstructuredMarkdownLoader, Docx2txtLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ad1968-efd4-4d6d-a870-5167e9388613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    state = {\n",
    "        \"folder_path\": None,\n",
    "        \"docs\": [],\n",
    "        \"vector_store\": None,\n",
    "        \"chat_graph\": None,\n",
    "        \"llm\": None,\n",
    "        \"prompt\": None,\n",
    "        \"initialized\": False,\n",
    "        \"embeddings\": None,\n",
    "        \"file_count\": 0,\n",
    "        \"processed_count\": 0\n",
    "    }\n",
    "    \n",
    "    def processPDF(pdf_path):\n",
    "        try:\n",
    "            #PyPDFLoader\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # If it works then return content\n",
    "            if docs and len(docs) > 0 and any(doc.page_content.strip() for doc in docs):\n",
    "                return docs\n",
    "                \n",
    "            # Otherwise try with UnstructuredLoader\n",
    "            try:\n",
    "                loader = UnstructuredLoader(\n",
    "                    file_path=pdf_path,\n",
    "                    strategy=\"hi_res\",\n",
    "                    partition_via_api=True,\n",
    "                    coordinates=True,\n",
    "                )\n",
    "                docs = list(loader.lazy_load())\n",
    "                if docs and len(docs) > 0:\n",
    "                    return docs\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            try:\n",
    "                loader = PDFPlumberLoader(pdf_path)\n",
    "                docs = loader.load()\n",
    "                if docs and len(docs) > 0:\n",
    "                    return docs\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            print(f\"Failed to extract content from {pdf_path} with any loader\")\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {pdf_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def processFiles():\n",
    "        try:\n",
    "            if not os.path.exists(state[\"folder_path\"]):\n",
    "                return False, f\"Folder not found: {state['folder_path']}\"\n",
    "            \n",
    "            all_files = []\n",
    "            for root, _, files in os.walk(state[\"folder_path\"]):\n",
    "                for file in files:\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    all_files.append(filepath)\n",
    "            \n",
    "            # Filter PDFs \n",
    "            pdf_extension = '.pdf'\n",
    "            files_to_process = [f for f in all_files if os.path.splitext(f)[1].lower() == pdf_extension]\n",
    "            \n",
    "            state[\"file_count\"] = len(files_to_process)\n",
    "            if state[\"file_count\"] == 0:\n",
    "                return False, f\"No PDF files found in {state['folder_path']}\"\n",
    "                \n",
    "            print(f\"Found {state['file_count']} PDF files to process\")\n",
    "            \n",
    "            state[\"docs\"] = []\n",
    "            state[\"processed_count\"] = 0\n",
    "            for file_path in files_to_process:\n",
    "                try:\n",
    "                    file_docs = processPDF(file_path)\n",
    "                    if file_docs:\n",
    "                        # Add source metadata to documents\n",
    "                        for doc in file_docs:\n",
    "                            if not hasattr(doc, 'metadata') or doc.metadata is None:\n",
    "                                doc.metadata = {}\n",
    "                            doc.metadata['source'] = os.path.basename(file_path)\n",
    "                            \n",
    "                        state[\"docs\"].extend(file_docs)\n",
    "                        state[\"processed_count\"] += 1\n",
    "                        print(f\"Processed {os.path.basename(file_path)}: {len(file_docs)} segments\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "            \n",
    "            if not state[\"docs\"] or len(state[\"docs\"]) == 0:\n",
    "                return False, \"No documents were successfully processed\"\n",
    "                \n",
    "            print(f\"Successfully processed {state['processed_count']}/{state['file_count']} files\")\n",
    "            print(f\"Total document segments: {len(state['docs'])}\")\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=2000,  \n",
    "                chunk_overlap=400, \n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "            )\n",
    "            \n",
    "            state[\"docs\"] = text_splitter.split_documents(state[\"docs\"])\n",
    "            print(f\"Split into {len(state['docs'])} chunks for processing\")\n",
    "            \n",
    "            return True, \"Files processed successfully\"\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error loading files: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return False, error_msg\n",
    "\n",
    "    def vectorStore():\n",
    "        try:\n",
    "            \n",
    "            print(\"Creating vector store...\")\n",
    "            state[\"vector_store\"] = FAISS.from_documents(state[\"docs\"], state[\"embeddings\"])\n",
    "            print(\"Vector store created successfully\")\n",
    "        except ImportError:\n",
    "            \n",
    "            print(\"Creating in-memory vector store...\")\n",
    "            state[\"vector_store\"] = InMemoryVectorStore.from_documents(state[\"docs\"], state[\"embeddings\"])\n",
    "            print(\"Vector store created successfully\")\n",
    "\n",
    "    def buildChatGraph():\n",
    "        print(\"Building chat graph...\")\n",
    "\n",
    "        class State(TypedDict):\n",
    "            question: str\n",
    "            context: List['Document']\n",
    "            answer: str\n",
    "        \n",
    "        # Create a better prompt template for more precise answers\n",
    "        system_template = \"\"\"You are an AI assistant specialized in providing accurate answers based on the provided PDF documents.\n",
    "        \n",
    "When answering questions:\n",
    "1. Only use information from the provided context.\n",
    "2. If the exact answer is in the context, quote it directly.\n",
    "3. Clearly indicate when information comes from the context.\n",
    "4. If you don't know or the context doesn't contain the answer, say so directly.\n",
    "5. Always cite the source PDF document name when providing information.\n",
    "6. Never make up information that isn't in the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "        state[\"prompt\"] = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_template),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "\n",
    "        def retrieve(graph_state: State) -> dict:\n",
    "            try:\n",
    "                retrieved_docs = state[\"vector_store\"].max_marginal_relevance_search(\n",
    "                    graph_state[\"question\"], \n",
    "                    k=6, \n",
    "                    fetch_k=10  \n",
    "                )\n",
    "            except:\n",
    "                # Fallback to regular similarity search\n",
    "                retrieved_docs = state[\"vector_store\"].similarity_search(\n",
    "                    graph_state[\"question\"],\n",
    "                    k=5  # Return more documents\n",
    "                )\n",
    "                \n",
    "            print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "            return {\"context\": retrieved_docs}\n",
    "\n",
    "        def generate(graph_state: State) -> dict:\n",
    "            \"\"\"Generate an answer based on the retrieved context\"\"\"\n",
    "            context_texts = []\n",
    "            for doc in graph_state[\"context\"]:\n",
    "                source = doc.metadata.get('source', 'Unknown source')\n",
    "                context_texts.append(f\"[PDF: {source}]\\n{doc.page_content}\")\n",
    "                \n",
    "            docs_content = \"\\n\\n\".join(context_texts)\n",
    "            \n",
    "            messages = state[\"prompt\"].invoke({\"question\": graph_state[\"question\"], \"context\": docs_content})\n",
    "            response = state[\"llm\"].invoke(messages)\n",
    "            return {\"answer\": response.content}\n",
    "\n",
    "        # Build the graph\n",
    "        graph_builder = StateGraph(State)\n",
    "        graph_builder.add_node(\"retrieve\", retrieve)\n",
    "        graph_builder.add_node(\"generate\", generate)\n",
    "        graph_builder.add_edge(START, \"retrieve\")\n",
    "        graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "        \n",
    "        state[\"chat_graph\"] = graph_builder.compile()\n",
    "\n",
    "    def initialize(folder_path=None):\n",
    "        if folder_path:\n",
    "            state[\"folder_path\"] = folder_path\n",
    "            \n",
    "        if not state[\"folder_path\"]:\n",
    "            return False, \"No folder path specified\"\n",
    "            \n",
    "        try:\n",
    "            from langchain.chat_models import init_chat_model\n",
    "            state[\"llm\"] = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "    \n",
    "            from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "            state[\"embeddings\"] = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    \n",
    "            success, message = processFiles()\n",
    "            if not success:\n",
    "                return False, message\n",
    "                \n",
    "            vectorStore()\n",
    "            buildChatGraph()\n",
    "    \n",
    "            state[\"initialized\"] = True\n",
    "            return True, \"Initialization successful\"\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Initialization error: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return False, error_msg\n",
    "\n",
    "    def chat(question):\n",
    "        if not state[\"initialized\"] or not state[\"chat_graph\"]:\n",
    "            return \"Chatbot not initialized. Please wait for initialization to complete.\"\n",
    "        \n",
    "        try:\n",
    "            result = state[\"chat_graph\"].invoke({\n",
    "                \"question\": question,\n",
    "                \"context\": [],\n",
    "                \"answer\": \"\"\n",
    "            })\n",
    "            return result[\"answer\"]\n",
    "        except Exception as e:\n",
    "            return f\"Error processing question: {str(e)}\"\n",
    "            \n",
    "    # Return the public API\n",
    "    return {\n",
    "        \"initialize\": initialize,\n",
    "        \"chat\": chat,\n",
    "        \"get_state\": lambda: {\n",
    "            \"initialized\": state[\"initialized\"],\n",
    "            \"processed_count\": state[\"processed_count\"],\n",
    "            \"file_count\": state[\"file_count\"]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f8cac2a-7159-4e42-9422-5a99bea49983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbot_ui():\n",
    "    \"\"\"Create the UI for the chatbot using closures for state management\"\"\"\n",
    "    # UI state\n",
    "    ui_state = {\n",
    "        \"chatbot\": chatbot(),\n",
    "        \"folder_path\": None,\n",
    "        \"root\": None\n",
    "    }\n",
    "    \n",
    "    def display_message(sender, message):\n",
    "        \"\"\"Display a message in the chat window\"\"\"\n",
    "        ui_state[\"chat_display\"].config(state=\"normal\")\n",
    "        ui_state[\"chat_display\"].insert(tk.END, f\"\\n{sender}: \", \"sender\")\n",
    "        ui_state[\"chat_display\"].insert(tk.END, f\"{message}\\n\")\n",
    "        ui_state[\"chat_display\"].config(state=\"disabled\")\n",
    "        ui_state[\"chat_display\"].see(tk.END)\n",
    "    \n",
    "    def ask_api_keys():\n",
    "        \"\"\"Prompt the user for required API keys\"\"\"\n",
    "        os.environ[\"LANGSMITH_API_KEY\"] = simpledialog.askstring(\"API Key\", \"Enter your LangSmith API Key:\")\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = simpledialog.askstring(\"API Key\", \"Enter your Google API Key:\")\n",
    "        os.environ[\"UNSTRUCTURED_API_KEY\"] = simpledialog.askstring(\"API Key\", \"Enter your Unstructured API Key (optional):\", initialvalue=\"\")\n",
    "    \n",
    "    def browse_folder():\n",
    "        \"\"\"Open folder browser dialog\"\"\"\n",
    "        folder = filedialog.askdirectory(title=\"Select Folder with PDF Documents\")\n",
    "        if folder:\n",
    "            ui_state[\"folder_path\"] = folder\n",
    "            ui_state[\"folder_path_var\"].set(folder)\n",
    "            ui_state[\"status_var\"].set(f\"Selected folder: {folder}\")\n",
    "    \n",
    "    def initialize_chatbot():\n",
    "        \"\"\"Initialize the chatbot with the selected folder\"\"\"\n",
    "        try:\n",
    "            success, message = ui_state[\"chatbot\"][\"initialize\"](ui_state[\"folder_path\"])\n",
    "            chatbot_state = ui_state[\"chatbot\"][\"get_state\"]()\n",
    "            if success:\n",
    "                ui_state[\"status_var\"].set(\"Ready\")\n",
    "                display_message(\"System\", f\"Chatbot initialized successfully. Processed {chatbot_state['processed_count']} PDF files.\")\n",
    "            else:\n",
    "                ui_state[\"status_var\"].set(\"Initialization failed\")\n",
    "                display_message(\"System\", f\"Failed to initialize chatbot: {message}\")\n",
    "        except Exception as e:\n",
    "            ui_state[\"status_var\"].set(\"Error\")\n",
    "            display_message(\"System\", f\"Error initializing chatbot: {e}\")\n",
    "    \n",
    "    def start_initialization():\n",
    "        \"\"\"Start the chatbot initialization in a separate thread\"\"\"\n",
    "        if not ui_state[\"folder_path\"]:\n",
    "            display_message(\"System\", \"Please select a folder containing PDF documents first\")\n",
    "            return\n",
    "            \n",
    "        ui_state[\"status_var\"].set(\"Initializing chatbot...\")\n",
    "        display_message(\"System\", f\"Initializing chatbot with folder: {ui_state['folder_path']}\")\n",
    "        Thread(target=initialize_chatbot).start()\n",
    "    \n",
    "    def process_question(question):\n",
    "        \"\"\"Process a user question in a separate thread\"\"\"\n",
    "        chatbot_state = ui_state[\"chatbot\"][\"get_state\"]()\n",
    "        if not chatbot_state[\"initialized\"]:\n",
    "            display_message(\"System\", \"Chatbot not initialized. Please initialize first.\")\n",
    "            ui_state[\"status_var\"].set(\"Ready\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            answer = ui_state[\"chatbot\"][\"chat\"](question)\n",
    "            display_message(\"Bot\", answer)\n",
    "            ui_state[\"status_var\"].set(\"Ready\")\n",
    "        except Exception as e:\n",
    "            display_message(\"Bot\", f\"Error processing question: {e}\")\n",
    "            ui_state[\"status_var\"].set(\"Error occurred\")\n",
    "    \n",
    "    def send_message(event=None):\n",
    "        \"\"\"Process and send user message\"\"\"\n",
    "        user_input = ui_state[\"entry\"].get().strip()\n",
    "        if not user_input:\n",
    "            return\n",
    "        display_message(\"You\", user_input)\n",
    "        ui_state[\"entry\"].delete(0, tk.END)\n",
    "        ui_state[\"status_var\"].set(\"Processing question...\")\n",
    "        Thread(target=process_question, args=(user_input,)).start()\n",
    "    \n",
    "    def setup_ui(root):\n",
    "        \"\"\"Set up the UI components\"\"\"\n",
    "        ui_state[\"root\"] = root\n",
    "        root.title(\"CTSE Chatbot\")\n",
    "        root.geometry(\"800x600\")  # Set a reasonable starting size\n",
    "        \n",
    "        # Ask for API keys first\n",
    "        ask_api_keys()\n",
    "        \n",
    "        # Create frames\n",
    "        control_frame = tk.Frame(root)\n",
    "        control_frame.pack(fill=tk.X, padx=10, pady=5)\n",
    "        \n",
    "        # Folder selection\n",
    "        tk.Label(control_frame, text=\"PDF Document Folder:\").pack(side=tk.LEFT, padx=(0, 5))\n",
    "        ui_state[\"folder_path_var\"] = tk.StringVar()\n",
    "        tk.Entry(control_frame, textvariable=ui_state[\"folder_path_var\"], width=40).pack(side=tk.LEFT, padx=(0, 5), fill=tk.X, expand=True)\n",
    "        tk.Button(control_frame, text=\"Browse\", command=browse_folder).pack(side=tk.LEFT, padx=(0, 5))\n",
    "        tk.Button(control_frame, text=\"Initialize\", command=start_initialization).pack(side=tk.LEFT)\n",
    "        \n",
    "        # Status bar\n",
    "        ui_state[\"status_var\"] = tk.StringVar(value=\"Ready\")\n",
    "        status_bar = tk.Label(root, textvariable=ui_state[\"status_var\"], bd=1, relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        # Chat display\n",
    "        chat_frame = tk.Frame(root)\n",
    "        chat_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)\n",
    "        \n",
    "        ui_state[\"chat_display\"] = scrolledtext.ScrolledText(chat_frame, wrap=tk.WORD, state=\"disabled\", height=25)\n",
    "        ui_state[\"chat_display\"].pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Entry field and send button\n",
    "        input_frame = tk.Frame(root)\n",
    "        input_frame.pack(fill=tk.X, padx=10, pady=5)\n",
    "        \n",
    "        ui_state[\"entry\"] = tk.Entry(input_frame, width=50)\n",
    "        ui_state[\"entry\"].pack(side=tk.LEFT, padx=(0, 5), fill=tk.X, expand=True)\n",
    "        ui_state[\"entry\"].bind(\"<Return>\", send_message)\n",
    "        \n",
    "        ui_state[\"send_button\"] = tk.Button(input_frame, text=\"Send\", command=send_message)\n",
    "        ui_state[\"send_button\"].pack(side=tk.RIGHT)\n",
    "        \n",
    "        # Add system welcome message\n",
    "        display_message(\"System\", \"Welcome! Please select a folder containing PDF documents and initialize the chatbot.\")\n",
    "    \n",
    "    # Return the public API\n",
    "    return {\n",
    "        \"setup_ui\": setup_ui\n",
    "    }\n",
    "\n",
    "# Main function to run the app\n",
    "def main():\n",
    "    root = tk.Tk()    \n",
    "    app = create_chatbot_ui()\n",
    "    app[\"setup_ui\"](root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b69c2a8-6780-48d3-a130-7d139c738917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 PDF files to process\n",
      "Processed AWS User Groups Colombo - Introduction to AWS Cloud Platform.pdf: 18 segments\n",
      "Processed CAP Theorem.pdf: 22 segments\n",
      "Processed Cloud Computing 101.pdf: 21 segments\n",
      "Processed Cloud Design Patterns - 1.pdf: 21 segments\n",
      "Processed Cloud Design Patterns - 2.pdf: 21 segments\n",
      "Processed cloud-computing-concepts-technology-amp-architecture-by-thomas-erl.pdf: 558 segments\n",
      "Processed Containers 101.pdf: 56 segments\n",
      "Processed Intro to DevOps and Beyond.pdf: 25 segments\n",
      "Processed Introduction to Microservices.pdf: 14 segments\n",
      "Processed Key Essentials for Building Application in Cloud.pdf: 41 segments\n",
      "Processed Lecture 2 - Part 1.pdf: 30 segments\n",
      "Processed Lecture 2 - Part 2.pdf: 8 segments\n",
      "Processed Microservice Design Patterns.pdf: 25 segments\n",
      "Processed ML Lec 2 - Part 1.pdf: 37 segments\n",
      "Processed ML Lec 2 - Part 2 LLM.pdf: 23 segments\n",
      "Successfully processed 15/15 files\n",
      "Total document segments: 920\n",
      "Split into 961 chunks for processing\n",
      "Creating vector store...\n",
      "Creating in-memory vector store...\n",
      "Vector store created successfully\n",
      "Building chat graph...\n",
      "Retrieved 6 documents\n",
      "Retrieved 6 documents\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63cf81-9994-4c94-97c4-ed43ca490561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
